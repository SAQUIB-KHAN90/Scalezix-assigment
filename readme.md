# **Web Scraper Chatbot - Integration Guide & Documentation**

## **ğŸ“Œ Project Overview**
The Web Scraper Chatbot is designed to **scrape web data** and provide **intelligent responses** to user queries. The project consists of:
- **Backend**: Built using **Node.js (Express.js)** with a Python-based scraper (`scrapper.py`).
- **Frontend**: Implemented inside **Jupyter Notebook (`.ipynb`)**.
- **AI Model**: Utilizes **Groq API** for generating chatbot responses.

---

## **ğŸ”§ Prerequisites**
Ensure you have the following installed:

### **For Backend**
âœ… Node.js (**Check with** `node -v`)
âœ… npm (**Check with** `npm -v`)
âœ… Python (**Check with** `python --version`)
âœ… Pip (**Check with** `pip --version`)
âœ… Required Node.js Packages:
   ```sh
   npm install express cors cookie-parser http-errors morgan ejs
   ```
âœ… Required Python Packages:
   ```sh
   pip install requests beautifulsoup4 chromadb langchain_groq tqdm
   ```

### **For Frontend (Jupyter Notebook)**
âœ… Jupyter Notebook (**Check with** `jupyter --version`)
âœ… Python Libraries:
   ```sh
   pip install notebook ipywidgets
   ```

---

## **ğŸ“‚ Project Structure**
```
Web_Scraper_Chatbot/
â”‚-- backend/
â”‚   â”‚-- app.js          # Main Express.js server
â”‚   â”‚-- scrapper.js     # Node.js script to call Python scraper
â”‚   â”‚-- scrapper.py     # Python web scraper & chatbot logic
â”‚   â”‚-- test1.py        # Alternative Python script
â”‚   â”‚-- package.json    # Node.js dependencies
â”‚   â”‚-- package-lock.json
â”‚-- frontend/
â”‚   â”‚-- Use_Chatbot_1.ipynb  # Jupyter Notebook Frontend
```

---

## **ğŸš€ Step 1: Run the Backend**
1ï¸âƒ£ **Navigate to the backend folder**:
```sh
cd path/to/Web_Scraper_Chatbot/backend
```

2ï¸âƒ£ **Install dependencies**:
```sh
npm install
```

3ï¸âƒ£ **Start the backend server**:
```sh
npm start
```
Expected Output:
```
Server running on http://localhost:3000
```

---

## **ğŸ–¥ï¸ Step 2: Start Jupyter Notebook (Frontend)**
1ï¸âƒ£ **Navigate to the frontend directory**:
```sh
cd path/to/Web_Scraper_Chatbot/frontend
```

2ï¸âƒ£ **Start Jupyter Notebook**:
```sh
jupyter notebook
```

3ï¸âƒ£ Open `Use_Chatbot_1.ipynb` and **run all cells**.

---

## **ğŸ”„ Step 3: API Integration (Backend & Frontend)**
### **Backend API Endpoints**
| Endpoint       | Method | Description |
|---------------|--------|-------------|
| `/query`      | POST   | Gets chatbot response from Groq API |
| `/crawl`      | POST   | Crawls a website and extracts links |
| `/scrape`     | POST   | Scrapes content from provided URLs |

### **Frontend API Calls (Using Python `requests`)**
#### **1ï¸âƒ£ Send Query to Chatbot**
```python
import requests
query = "What is web scraping?"
response = requests.post("http://localhost:3000/query", json={"query": query})
print(response.json())
```

#### **2ï¸âƒ£ Crawl URLs**
```python
homepage = "https://example.com"
response = requests.post("http://localhost:3000/crawl", json={"homepage": homepage, "maxPages": 5})
print(response.json())
```

#### **3ï¸âƒ£ Scrape Website Content**
```python
urls = ["https://example.com/page1", "https://example.com/page2"]
response = requests.post("http://localhost:3000/scrape", json={"urls": urls})
print(response.json())
```

---

## **ğŸ›  Step 4: Convert Notebook to Python Script (Optional)**
If you want to run the chatbot as a Python script instead of using Jupyter Notebook:
```sh
jupyter nbconvert --to script Use_Chatbot_1.ipynb
python Use_Chatbot_1.py
```

---

## **ğŸ“Œ Step 5: Deployment Guide (Optional)**
To deploy the chatbot online:
- **Backend**: Deploy Node.js on **AWS EC2, Heroku, or Railway.app**.
- **Frontend**: Convert to a web UI using Flask/Streamlit or deploy Jupyter Notebook.

---

## **âš ï¸ Error Handling & Troubleshooting**
### **1ï¸âƒ£ Backend Not Starting?**
ğŸ”¹ Run `npm install` to reinstall dependencies.  
ğŸ”¹ Check for errors in `app.js`.

### **2ï¸âƒ£ Jupyter Notebook Not Opening?**
ğŸ”¹ Run `pip install notebook` again.  
ğŸ”¹ Try `jupyter notebook --generate-config`.

### **3ï¸âƒ£ API Not Responding?**
ğŸ”¹ Make sure the backend is running (`npm start`).  
ğŸ”¹ Use `curl` to check API manually:
```sh
curl -X POST http://localhost:3000/query -H "Content-Type: application/json" -d '{"query": "Hello"}'
```

---

## **âœ… Conclusion**
You have now successfully:
- Integrated the **backend (Node.js & Python)** with the **frontend (Jupyter Notebook)**.
- Connected the **chatbot UI** with the **web scraper**.
- Tested API calls for **chatbot queries, web crawling, and scraping**.

ğŸ“Œ **Next Steps**: Deploy the chatbot, improve UI, or extend functionalities. ğŸš€

---

### **ğŸ’¡ Need Further Assistance?**
Feel free to ask for help in debugging, hosting, or improving the chatbot! ğŸ¯

